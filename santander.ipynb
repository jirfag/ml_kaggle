{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(76020, 369) (76020,)\n",
      "0    73012\n",
      "1     3008\n",
      "Name: TARGET, dtype: int64\n",
      "CPU times: user 8.81 s, sys: 780 ms, total: 9.59 s\n",
      "Wall time: 10.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "RANDOM_STATE = 42\n",
    "import pandas as pd\n",
    "train_data = pd.read_csv('train.csv', index_col='ID')\n",
    "test_data = pd.read_csv('test.csv', index_col='ID')\n",
    "\n",
    "y_train = train_data['TARGET']\n",
    "X_train = train_data.drop(['TARGET'], axis=1)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(y_train.value_counts())\n",
    "assert not (X_train.count() != y_train.shape[0]).any() # ensure that there is no missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data transformation removed 63/369 features\n",
      "CPU times: user 7.45 s, sys: 100 ms, total: 7.55 s\n",
      "Wall time: 7.61 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, VarianceThreshold\n",
    "import numpy as np\n",
    "\n",
    "def remove_constant_features(X):\n",
    "    s = VarianceThreshold()\n",
    "    s.fit(X)\n",
    "    return s.transform\n",
    "\n",
    "def get_best_features(X, y):\n",
    "    selectK = SelectKBest(f_classif, k=250)\n",
    "    selectK.fit(X, y)\n",
    "    return selectK.transform\n",
    "\n",
    "def replace_outliers_with_mean(X):\n",
    "    for col in X.columns:\n",
    "        mean, std = X[col].mean(), X[col].std()\n",
    "        outliers = (X[col] - mean).abs() > 3 * std\n",
    "        X[outliers] = X[col][~outliers].mean()\n",
    "    return X\n",
    "\n",
    "def remove_dup_cols(X):\n",
    "    remove = []\n",
    "    df = pd.DataFrame(X)\n",
    "    c = df.columns\n",
    "    for i in range(len(c)-1):\n",
    "        v = df[c[i]].values\n",
    "        for j in range(i+1,len(c)):\n",
    "            if np.array_equal(v, df[c[j]].values):\n",
    "                remove.append(c[j])\n",
    "                \n",
    "    def tr(x):\n",
    "        return pd.DataFrame(x).drop(remove, axis=1)\n",
    "    return tr\n",
    "    \n",
    "def data_fit_transform(X, y):\n",
    "#    X = X.replace(-999999, 2)#9999999999\n",
    "    \n",
    "    cf = remove_constant_features(X)\n",
    "    X = cf(X)\n",
    "    \n",
    "    rdc = remove_dup_cols(X)\n",
    "    X = rdc(X)\n",
    " \n",
    "# XXX: it decreses auc on train set, don't use\n",
    "# BUT: one time it increased auc on test set for 0.003\n",
    "#    bf = get_best_features(X, y)\n",
    "#    X = bf(X) \n",
    "\n",
    "# XXX: it dramatically decreses auc on train set, don't use\n",
    "#df = pd.DataFrame(x)\n",
    "#return replace_outliers_with_mean(df)\n",
    "    \n",
    "    def tr(x):\n",
    "        return rdc(cf(x))\n",
    "    \n",
    "    return tr, X\n",
    "\n",
    "data_transformer, X_train_transformed = data_fit_transform(X_train, y_train)\n",
    "print('data transformation removed {}/{} features'.format(X_train.shape[1] - X_train_transformed.shape[1], X_train.shape[1]))\n",
    "X_test_transformed = data_transformer(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with rank: 1\n",
      "Mean validation score: 0.858 (std: 0.085)\n",
      "Parameters: {'n_estimators': 1000, 'seed': 42, 'nthread': 4, 'subsample': 0.60000000000000009, 'max_depth': 6, 'learning_rate': 0.1979282234579941, 'colsample_bytree': 0.65000000000000013}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.855 (std: 0.064)\n",
      "Parameters: {'n_estimators': 1000, 'seed': 42, 'nthread': 4, 'subsample': 0.29999999999999999, 'max_depth': 6, 'learning_rate': 0.1979282234579941, 'colsample_bytree': 0.95000000000000007}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.850 (std: 0.034)\n",
      "Parameters: {'n_estimators': 1000, 'seed': 42, 'nthread': 4, 'subsample': 0.90000000000000013, 'max_depth': 5, 'learning_rate': 0.11214482728762599, 'colsample_bytree': 0.95000000000000007}\n",
      "\n",
      "Model with rank: 4\n",
      "Mean validation score: 0.850 (std: 0.039)\n",
      "Parameters: {'n_estimators': 1000, 'seed': 42, 'nthread': 4, 'subsample': 0.90000000000000013, 'max_depth': 5, 'learning_rate': 0.049480389963296491, 'colsample_bytree': 0.60000000000000009}\n",
      "\n",
      "Model with rank: 5\n",
      "Mean validation score: 0.842 (std: 0.060)\n",
      "Parameters: {'n_estimators': 1000, 'seed': 42, 'nthread': 4, 'subsample': 0.80000000000000004, 'max_depth': 5, 'learning_rate': 0.11214482728762599, 'colsample_bytree': 0.90000000000000013}\n",
      "\n",
      "CPU times: user 26.6 s, sys: 7.96 s, total: 34.6 s\n",
      "Wall time: 34.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def report(grid_scores, n_top=3):\n",
    "    import numpy as np\n",
    "    from operator import itemgetter\n",
    "    top_scores = sorted(grid_scores, key=itemgetter(1), reverse=True)[:n_top]\n",
    "    for i, score in enumerate(top_scores):\n",
    "        print(\"Model with rank: {0}\".format(i + 1))\n",
    "        print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "              score.mean_validation_score,\n",
    "              np.std(score.cv_validation_scores)))\n",
    "        print(\"Parameters: {0}\".format(score.parameters))\n",
    "        print(\"\")\n",
    "\n",
    "def find_best_xgb_params(X, y, n_iter):\n",
    "    import xgboost as xgb\n",
    "    import numpy as np\n",
    "    from sklearn.grid_search import RandomizedSearchCV\n",
    "\n",
    "    clf = xgb.XGBClassifier(missing=np.nan, seed=RANDOM_STATE)\n",
    "    param_distributions = {\n",
    "        'max_depth': np.arange(2, 8),\n",
    "        'n_estimators': [1000], # early stop helps us\n",
    "        'learning_rate': np.random.uniform(0.001, 0.2, 30),\n",
    "        'nthread': [4],\n",
    "        'subsample': np.arange(0.05, 1.05, 0.05),\n",
    "        'colsample_bytree': np.arange(0.05, 1.05, 0.05),\n",
    "#        'colsample_bylevel': np.arange(0.1, 1.1, 0.1),\n",
    "        'seed': [RANDOM_STATE],\n",
    "#        'scale_pos_weight': np.arange(0, 1.1, 0.1),\n",
    "#        'reg_lambda': np.arange(0, 1.1, 0.1),\n",
    "#        'reg_alpha': np.arange(0, 1.1, 0.1),\n",
    "#        'gamma': np.arange(0, 1.1, 0.1),\n",
    "    }\n",
    "    fit_params = {'early_stopping_rounds': 30, 'eval_metric': \"auc\", 'verbose': False, 'eval_set': [(X, y)]}\n",
    "    rs = RandomizedSearchCV(estimator=clf, param_distributions=param_distributions,\n",
    "                            n_iter=n_iter, n_jobs=1, refit=False,\n",
    "                            cv=3, random_state=RANDOM_STATE,\n",
    "                            scoring='roc_auc', fit_params=fit_params, verbose=1)\n",
    "\n",
    "    rs.fit(X, y)\n",
    "    return rs\n",
    "\n",
    "subsamples_n = 200\n",
    "rs = find_best_xgb_params(X_train_transformed.sample(subsamples_n, random_state=RANDOM_STATE),\n",
    "                          y_train.sample(subsamples_n, random_state=RANDOM_STATE), 100)\n",
    "report(rs.grid_scores_, n_top=5)\n",
    "# on 5k:\n",
    "#Model with rank: 1\n",
    "#Mean validation score: 0.823 (std: 0.008)\n",
    "#Parameters: {'max_depth': 7, 'reg_lambda': 0.75000000000000011, 'seed': 4242, 'colsample_bytree': 0.15000000000000002, 'n_estimators': 700, 'gamma': 0.80000000000000004, 'scale_pos_weight': 0.65000000000000013, 'nthread': 4, 'learning_rate': 0.16590859024207197, 'colsample_bylevel': 0.90000000000000013, 'subsample': 0.45000000000000001, 'reg_alpha': 0.95000000000000007}\n",
    "\n",
    "# 1k:\n",
    "# ===\n",
    "#Model with rank: 1\n",
    "#Mean validation score: 0.810 (std: 0.040)\n",
    "#Parameters: {'max_depth': 2, 'reg_lambda': 0.75000000000000011, 'seed': 4242, 'colsample_bytree': 0.55000000000000004, 'n_estimators': 700, 'gamma': 0.90000000000000002, 'scale_pos_weight': 0.40000000000000002, 'nthread': 4, 'learning_rate': 0.18509478318796457, 'colsample_bylevel': 0.65000000000000013, 'subsample': 0.95000000000000007, 'reg_alpha': 1.0}\n",
    "\n",
    "\n",
    "#Model with rank: 1\n",
    "#Mean validation score: 0.818 (std: 0.041)\n",
    "#Parameters: {'max_depth': 1, 'reg_lambda': 0.0, 'seed': 4242, 'colsample_bytree': 0.90000000000000002, 'n_estimators': 230, 'gamma': 0.80000000000000004, 'scale_pos_weight': 0.60000000000000009, 'nthread': 4, 'learning_rate': 0.16432489935422318, 'colsample_bylevel': 0.40000000000000002, 'subsample': 0.90000000000000002, 'reg_alpha': 0.90000000000000002}\n",
    "\n",
    "#Model with rank: 4\n",
    "#Mean validation score: 0.815 (std: 0.035)\n",
    "#Parameters: {'max_depth': 1, 'reg_lambda': 0.30000000000000004, 'seed': 4242, 'colsample_bytree': 0.59999999999999998, 'n_estimators': 830, 'gamma': 0.60000000000000009, 'scale_pos_weight': 0.30000000000000004, 'nthread': 4, 'learning_rate': 0.16106270282244134, 'colsample_bylevel': 0.70000000000000007, 'subsample': 1.0, 'reg_alpha': 0.20000000000000001}\n",
    "\n",
    "#Model with rank: 3\n",
    "#Mean validation score: 0.850 (std: 0.034)\n",
    "#Parameters: {'n_estimators': 1000, 'seed': 42, 'nthread': 4, 'subsample': 0.90000000000000013, 'max_depth': 5, 'learning_rate': 0.11214482728762599, 'colsample_bytree': 0.95000000000000007}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Will train until cv error hasn't decreased in 20 rounds.\n",
      "[0]\tcv-test-auc:0.7925904+0.003893049221368766\tcv-train-auc:0.8062403999999999+0.0041545556007833145\n",
      "[1]\tcv-test-auc:0.8049076+0.002897922952737004\tcv-train-auc:0.8225979999999999+0.0055345190576959555\n",
      "[2]\tcv-test-auc:0.8114684000000001+0.006108599728251982\tcv-train-auc:0.834536+0.0040347851987435285\n",
      "[3]\tcv-test-auc:0.8136671999999999+0.007995657556448982\tcv-train-auc:0.8415526+0.0038074918568527494\n",
      "[4]\tcv-test-auc:0.8118451999999999+0.0074994640448501505\tcv-train-auc:0.8442172000000001+0.0033283632253706774\n",
      "[5]\tcv-test-auc:0.8138852+0.009564554070106967\tcv-train-auc:0.8484242+0.003020876389394317\n",
      "[6]\tcv-test-auc:0.8175866+0.0074359206719814\tcv-train-auc:0.8536376000000001+0.0022591264329381803\n",
      "[7]\tcv-test-auc:0.8185775999999999+0.0075122929815070565\tcv-train-auc:0.8555984000000001+0.0025622172117133087\n",
      "[8]\tcv-test-auc:0.8188704+0.007011005308798471\tcv-train-auc:0.8577750000000002+0.002459494175638592\n",
      "[9]\tcv-test-auc:0.8203258+0.0054596506994495685\tcv-train-auc:0.8603832+0.0037156058671500734\n",
      "[10]\tcv-test-auc:0.820247+0.005209106180526554\tcv-train-auc:0.8634613999999999+0.003191722957902195\n",
      "[11]\tcv-test-auc:0.8190035999999999+0.006191747720958909\tcv-train-auc:0.8649582+0.003349128925556606\n",
      "[12]\tcv-test-auc:0.8180422+0.006978610560849477\tcv-train-auc:0.8678072+0.0027547417592217313\n",
      "[13]\tcv-test-auc:0.8169296000000001+0.005705559134738676\tcv-train-auc:0.8696577999999999+0.002349944969568463\n",
      "[14]\tcv-test-auc:0.8172146+0.0063053145393389895\tcv-train-auc:0.8706728+0.002436161768027746\n",
      "[15]\tcv-test-auc:0.8158072000000001+0.008679217301116501\tcv-train-auc:0.8718286000000001+0.002333688033992543\n",
      "[16]\tcv-test-auc:0.8163076+0.00840773916341368\tcv-train-auc:0.8732082+0.002196705205529402\n",
      "[17]\tcv-test-auc:0.8165316+0.008362351214819909\tcv-train-auc:0.8746212+0.0029640211470230654\n",
      "[18]\tcv-test-auc:0.8162043999999999+0.009355143795794926\tcv-train-auc:0.8754932+0.0026815445101657466\n",
      "[19]\tcv-test-auc:0.815663+0.008477773410512942\tcv-train-auc:0.8765744+0.00296914429423699\n",
      "[20]\tcv-test-auc:0.8153524000000001+0.00822116017603357\tcv-train-auc:0.8774067999999999+0.002503073742421489\n",
      "[21]\tcv-test-auc:0.8153188+0.008060009538455886\tcv-train-auc:0.8780566000000001+0.0020764082064950802\n",
      "[22]\tcv-test-auc:0.8151088+0.007805713430558424\tcv-train-auc:0.8785798+0.0019142204052825218\n",
      "[23]\tcv-test-auc:0.8146498+0.006814883517713249\tcv-train-auc:0.8797696+0.0018354406119512594\n",
      "[24]\tcv-test-auc:0.8148728000000001+0.00674822217772946\tcv-train-auc:0.8804428+0.0014130485341983334\n",
      "[25]\tcv-test-auc:0.8144058000000001+0.006492295476948031\tcv-train-auc:0.8814858000000001+0.0016253225402977464\n",
      "[26]\tcv-test-auc:0.8148692000000001+0.006479708215652932\tcv-train-auc:0.8823357999999999+0.0019787503531269327\n",
      "[27]\tcv-test-auc:0.8153310000000001+0.006305418748980927\tcv-train-auc:0.8826997999999999+0.0021364637511551666\n",
      "[28]\tcv-test-auc:0.8145544000000001+0.0070551341759034\tcv-train-auc:0.8834862000000001+0.0020128215420150922\n",
      "[29]\tcv-test-auc:0.8144045999999999+0.0071532641667982535\tcv-train-auc:0.8840042+0.0016973171064948239\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 3s, sys: 1.56 s, total: 1min 4s\n",
      "Wall time: 1min 5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stopping. Best iteration:\n",
      "[9] cv-mean:0.8203258\tcv-std:0.0054596506994495685\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "# also working params: missing=9999999999, max_depth = 4, n_estimators=200, learning_rate=0.001,\n",
    "# nthread=4, subsample=0.75, colsample_bytree=0.75, seed=4242\n",
    "\n",
    "clf_params_from_kaggle_scripts = {'max_depth': 5, 'learning_rate': 0.03,\n",
    "                                  'subsample': 0.95, 'colsample_bytree': 0.85}\n",
    "\n",
    "clf_params = dict(clf_params_from_kaggle_scripts)\n",
    "clf_params['missing'] = np.nan\n",
    "clf_params['seed'] = RANDOM_STATE\n",
    "clf_params['nthread'] = 4\n",
    "clf_params['n_estimators'] = 1000\n",
    "\n",
    "def do_xgb_cv(X, y):\n",
    "    dtrain = xgb.DMatrix(X, label=y, missing=clf_params['missing'])\n",
    "    xgb.cv(clf_params, dtrain, clf_params['n_estimators'], nfold=5, metrics='auc',\n",
    "           early_stopping_rounds=20, verbose_eval=True, seed=RANDOM_STATE)\n",
    " \n",
    "def xgb_predict(X_train, y_train, X_test, **add_params):\n",
    "    params = dict(clf_params)\n",
    "    params.update(add_params)\n",
    "    clf = xgb.XGBClassifier(**clf_params)\n",
    "    clf.fit(X_train, y_train, early_stopping_rounds=20, eval_metric=\"auc\", verbose=True,\n",
    "            eval_set=[(X_train, y_train)])\n",
    "    \n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    print('xgb auc:', clf.best_iteration,\n",
    "          roc_auc_score(y_train, clf.predict_proba(X_train, ntree_limit=clf.best_iteration)[:,1]))\n",
    "    \n",
    "    return clf.predict_proba(X_test, ntree_limit=clf.best_iteration)[:,1]\n",
    "\n",
    "# ipython crashes often on full collection, so run on subcollection\n",
    "do_xgb_cv(X_train_transformed[:40000], y_train[:40000])\n",
    "\n",
    "#y_pred = xgb_predict(X_train_transformed, y_train, X_test_transformed)\n",
    "#submission = pd.DataFrame({\"ID\": test_data.index, \"TARGET\": y_pred})\n",
    "#submission.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb: 0.83588 for 29.8 sec\n",
      "gbt: 0.83175 for 29.0 sec\n",
      "random_forest: 0.75196 for 32.4 sec\n",
      "extra_trees: 0.69849 for 38.8 sec\n",
      "ada_boost: 0.81779 for 4.5 sec\n",
      "lin_reg: 0.78822 for 4.7 sec\n",
      "dec_tree: 0.57324 for 6.8 sec\n",
      "svm: 0.29054 for 2.6 sec\n",
      "knn: 0.52334 for 13.8 sec\n",
      "sgd: 0.62868 for 2.1 sec\n",
      "bayes_ridge: 0.77733 for 13.1 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.4/site-packages/sklearn/linear_model/coordinate_descent.py:474: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations\n",
      "  ConvergenceWarning)\n",
      "/opt/conda/lib/python3.4/site-packages/sklearn/linear_model/coordinate_descent.py:474: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elastic_net: 0.69058 for 48.0 sec\n",
      "log_reg: 0.60418 for 6.3 sec\n",
      "perceptron: 0.62868 for 2.1 sec\n"
     ]
    }
   ],
   "source": [
    "def compare_estimators():\n",
    "    import time\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "\n",
    "    from sklearn import svm\n",
    "    from sklearn.ensemble import GradientBoostingClassifier\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    from sklearn.linear_model import SGDClassifier, BayesianRidge, ElasticNet, LinearRegression, LogisticRegression, Perceptron\n",
    "    from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier\n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    "    import xgboost as xgb\n",
    "\n",
    "    estimators = [\n",
    "                  {'name': 'xgb', 'clf': xgb.XGBClassifier, 'params': {'no_random_state': True}, 'clf_params': {'n_estimators': 40, 'learning_rate': 0.2}},\n",
    "                  {'name': 'gbt', 'clf': GradientBoostingClassifier, 'clf_params': {'n_estimators': 40, 'learning_rate': 0.2}},\n",
    "                  {'name': 'random_forest', 'clf': RandomForestClassifier, 'clf_params': {'n_estimators': 100, 'n_jobs': 4}},\n",
    "                  {'name': 'extra_trees', 'clf': ExtraTreesClassifier, 'clf_params': {'n_estimators': 100, 'n_jobs': 2}},\n",
    "                  {'name': 'ada_boost', 'clf': AdaBoostClassifier,\n",
    "                   'clf_params': {'n_estimators': 10}},\n",
    "                  {'name': 'lin_reg', 'clf': LinearRegression, 'params': {'no_random_state': True}},\n",
    "\n",
    "                  {'name': 'dec_tree', 'clf': DecisionTreeClassifier},\n",
    "\n",
    "                  {'name': 'svm', 'clf': svm.SVC, 'clf_params': {'kernel': 'linear', 'tol': 1e-1}, 'params': {'subsamples_n': 0.002}},\n",
    "                  {'name': 'knn', 'clf': KNeighborsClassifier, 'params': {'no_random_state': True, 'subsamples_n': 0.1}},\n",
    "                  {'name': 'sgd', 'clf': SGDClassifier},\n",
    "                  {'name': 'bayes_ridge', 'clf': BayesianRidge, 'params': {'no_random_state': True}},\n",
    "                  {'name': 'elastic_net', 'clf': ElasticNet},\n",
    "                  {'name': 'log_reg', 'clf': LogisticRegression},\n",
    "                  {'name': 'perceptron', 'clf': Perceptron},\n",
    "                 ]\n",
    "\n",
    "    for e in estimators:\n",
    "        start_time = time.time()\n",
    "        clf_class = e['clf']\n",
    "        clf_params = dict(e.get('clf_params', {}))\n",
    "        params = e.get('params', {})\n",
    "        if not params.get('no_random_state'):\n",
    "            clf_params['random_state'] = RANDOM_STATE\n",
    "        if params.get('subsamples_n'):\n",
    "            subsamples_n = int(X_train.shape[0] * params['subsamples_n'])\n",
    "            x, y = X_train[:subsamples_n], y_train[:subsamples_n]\n",
    "        else:\n",
    "            x, y = X_train, y_train\n",
    "\n",
    "        clf = clf_class(**clf_params)\n",
    "        r = cross_val_score(clf, x, y,\n",
    "                            cv=2, n_jobs=4, scoring='roc_auc').mean()\n",
    "        print('{}: {:.5f} for {:.1f} sec'.format(e['name'], r, time.time() - start_time))\n",
    "        \n",
    "compare_estimators()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
